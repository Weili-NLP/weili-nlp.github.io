<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>Wei Li's Homepage</title>
<meta id="viewport" name="viewport" content="width=500" />
<meta name="description" content="Wei Li is a researcher in Natural Language Processing" />


<link rel="stylesheet" href="./theme/css/normalize.css" type="text/css" /> 
<link rel="stylesheet" href="./theme/css/base.css" type="text/css" /> 
<link rel="stylesheet" href="./theme/css/code.css" type="text/css" />

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110992267-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110992267-1');
</script>

<!-- 
<link rel="icon" type="image/png" href="./theme/images/avatar.png" sizes="200x200">
<link rel="icon" type="image/png" href="./theme/images/favicon.png" sizes="32x32"> -->
</head>

<body>

<div class="content">

    <header>
        <img src="./theme/images/photo.png" alt="me">
        <h1>Wei Li（李伟）</h1>
        <ul>
            <!--<li><a href="./#pubs">Publications</a></li>
            <li><a href="./#projects">Projects</a></li>
            <li><a href="./#backgroud">Backgroud</a></li>
            <li><a href="./resume.pdf">CV</a></li>
            <li><a href="mailto:cs-ly@pku.edu.cn"</a>Contact</li> -->
        </ul>
    </header>

<section id="bio">
    <h2>About Me</h2>
    <p>I am an Associate Professor at the Institute of Computing Technology, Chinese Academy of Sciences. My journey in this field began at the same institute, where I earned my Ph.D. in 2019.</p>

    <p>My research primarily explores the fields of <b>Cross-Modal Generation</b>, <b>Natural Language Generation</b>, and <b>Multi-modal Learning</b>. A significant aspect of my work is dedicated to UNIfied-MOdal learning (<a href="https://unimo-ptm.github.io/">UNIMO</a>). This approach aims to integrate various data modalities, such as text, images, and other modalities, for advanced multimodal understanding and generation.</p>

    <p>For a detailed look at my work and researches, feel free to explore my academic profiles: <a href="https://scholar.google.com/citations?user=34xQzZ4AAAAJ&hl=zh-CN">Google Scholar</a>, <a href="https://dblp.org/pid/64/6025-176">DBLP</a>. If you have any inquiries or wish to discuss academic collaborations, please do not hesitate to <a href="mailto:weili.ucas.ict@gmail.com">email me</a>.</p>
</section>

<section id="news">
    <h3>News:</h3>
    <ul>
        <li>[2024.05.16] <mark>4 paper</mark> have been accepted by ACL 2024, 3 Main Conference + 1 Findings.</li>
        <li>[2023.05.02] <mark>1 paper</mark> (WeCheck) for NLG factuality evaluation, has been accepted by ACL 2023, Main Conference.</li>
        <li>[2023.04.27] <mark>1 paper</mark> (FactGen) for faithful text generation, has been accepted by Journal of Artificial Intelligence Research, 2023.</li>
        <li>[2022.10.07] <mark>3 paper</mark> have been accepted by EMNLP 2022, 1 Main Conference + 2 Findings.</li>
        <li>[2022.03.10] <mark>A survey</mark> on faithfulness in natural language generation has been published on arxiv.</li>
        <li>[2022.02.24] <mark>2 paper</mark> have been accepted by ACL 2022, 1 Main Conference + 1 Findings.</li>
        <li>[2021.08.26] <mark>1 paper</mark> has been accepted by EMNLP 2021, Main Conference.</li>
        <li>[2021.05.06] <mark>3 paper</mark> have been accepted by ACL 2021, Main Conference.</li>
        <li>[2021.04.14] <mark>1 paper</mark> has been accepted by SIGIR 2021, Full Paper.</li>
        <li>[2020.04.03] <mark>1 paper</mark> has been accepted by ACL 2020, Main Conference.</li>
    </ul>
</section>

<section id="pubs">
    <h2>Publications:</h2>
    <ul>
        <li> <b>[ACL 2024]</b> <u>Wei Li*</u>, Xue Xu*, Jiachen Liu, Xinyan Xiao. <i>UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion.</i> [<a href="https://arxiv.org/pdf/2401.13388.pdf">PDF</a>] [<a href="https://github.com/Weili-NLP/UNIMO-G">code</a>]
        </li>

        <li> <b>[ACL 2024]</b> Wenhao Wu, <u>Wei Li*</u>, Xinyan Xiao, Jiachen Liu, Sujian Li. <i>InstructEval: Instruction-Tuned Text Evaluator from Human Preference.</i> [<a href="https://openreview.net/pdf?id=DvzCPiMprdxK">PDF</a>]
        </li>

        <li> <b>[ACL 2024]</b> Xuhui Jiang, Yinghan Shen, Zhichao Shi, Chengjin Xu, <u>Wei Li*</u>, Zixuan Li, Jian Guo, Huawei Shen, Yuanzhuo Wang. <i>Unlocking the Power of Large Language Models for Entity Alignment.</i> [<a href="https://arxiv.org/pdf/2402.15048">PDF</a>]
        </li>

        <li> <b>[ACL 2024]</b> Zixuan Li, Yutao Zeng, Yuxin Zuo, Weicheng Ren, Wenxuan Liu, Miao Su, Yucan Guo, Yantao Liu, Xiang Li, Zhilei Hu, Long Bai, <u>Wei Li*</u>, Yidan Liu, Pan Yang, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng. <i>KnowCoder: Coding Structured Knowledge into LLMs for Universal Information Extraction.</i> [<a href="https://arxiv.org/pdf/2403.07969">PDF</a>] [<a href="https://ict-goknow.github.io/knowcoder/">code</a>]
        </li>

        <li> <b>[ACL 2023]</b> Wenhao Wu, <u>Wei Li</u>, Xinyan Xiao, Jiachen Liu, Sujian Li and Yajuan Lyu. <i>WeCheck: Strong Factual Consistency Checker via Weakly Supervised Learning.</i>. Main Confereance of ACL 2023, long paper. [<a href="https://aclanthology.org/2023.acl-long.18.pdf">PDF</a>] [<a href="https://huggingface.co/nightdessert/WeCheck">code</a>]
        </li>

        <li> <b>[JAIR 2023]</b> Zhibin Lan, <u>Wei Li</u>, Jinsong Su, Xinyan Xiao, Jiachen Liu, Wenhao Wu, Yajuan Lyu. <i>FactGen: Faithful Text Generation by Factuality-aware Pre-training and Contrastive Ranking Fine-tuning.</i> Journal of Artificial Intelligence Research, 2023.
        </li>

        <li> <b>[Arxiv 2022]</b> <u>Wei Li</u>, Xue Xu, Xinyan Xiao, Jiachen Liu, Hu Yang, Guohao Li, Zhanpeng Wang, Zhifan Feng, Qiaoqiao She, Yajuan Lyu, Hua Wu. <i>UPainting: Unified Text-to-Image Diffusion Generation with Cross-modal Guidance.</i> [<a href="https://arxiv.org/pdf/2210.16031.pdf">PDF</a>] [<a href="https://upainting.github.io/">code</a>]
        </li>

        <li> <b>[EMNLP 2022]</b> Wenhao Wu, <u>Wei Li</u>, Jiachen Liu, Xinyan Xiao, Sujian Li and Yajuan Lyu. <i>Precisely the Point: Adversarial Augmentations for Faithful and Informative Text Generation.</i>. Main Confereance of EMNLP 2022, long paper.
        </li>
        
        <li> <b>[EMNLP 2022]</b> Wenhao Wu, <u> Wei Li </u>, Jiachen Liu, Xinyan Xiao, Ziqiang Cao, Sujian Li and Hua Wu. <i>FRSUM: Towards Faithful Abstractive Summarization via Enhancing Factual Robustness</i>. Findings of EMNLP 2022, long paper.
        </li>
        
        <li> <b>[EMNLP 2022]</b> Zixuan Li, Zhongni Hou, Saiping Guan, Xiaolong Jin, Weihua Peng, Long Bai, Yajuan Lyu, <u>Wei Li</u>, Jiafeng Guo and Xueqi Cheng. <i>HiSMatch: Historical Structure Matching based Temporal Knowledge Graph Reasoning</i>. Findings of EMNLP 2022, long paper [<a href="https://arxiv.org/abs/2203.09067">PDF</a>] [<a href="https://unimo-ptm.github.io/">code</a>]
        </li>

        <li> <b>[Arxiv 2022]</b> <u>Wei Li</u>, Wenhao Wu, Moye Chen, Jiachen Liu, Xinyan Xiao and Hua Wu. <i>Faithfulness in Natural Language Generation: A Systematic Survey of Analysis, Evaluation and Optimization Methods</i> (52 pages). [<a href="https://arxiv.org/pdf/2203.05227.pdf">PDF</a>]
        </li>

        <li> <b>[ACL 2022]</b> <u>Wei Li</u>, Can Gao, Guochenng Niu, Xinyan Xiao, Hao Liu, Jiachen Liu, Hua Wu and Haifeng Wang. <i>End-to-End Unified Vision-Language Grounded Learning</i>. Findings of ACL 2022, long paper [<a href="https://arxiv.org/abs/2203.09067">PDF</a>] [<a href="https://unimo-ptm.github.io/">code</a>]
        </li>

        <li> <b>[ACL 2022]</b> Zixuan Li, Saiping Guan, Xiaolong Jin, Weihua Peng, Yajuan Lyu, Yong Zhu, Long Bai, <u>Wei Li</u>, Jiafeng Guo, Xueqi Cheng. <i>Complex Evolutional Pattern Learning for Temporal Knowledge Graph Reasoning</i>. ACL 2022, short paper, Main Conference. [<a href="https://arxiv.org/pdf/2203.07782.pdf">PDF</a>]
        </li>

        <li> <b>[EMNLP 2021]</b> Moye Chen*, <u>Wei Li*</u>, Jiachen Liu, Xinyan Xiao, Hua Wu and Haifeng Wang. <i>SgSum: Transforming Multi-document Summarization into Sub-graph Selection</i>. EMNLP 2021 long paper, Main Conference. (* indicates equal contribution) [<a href="https://aclanthology.org/2021.emnlp-main.333.pdf">PDF</a>] [<a href="https://github.com/PaddlePaddle/Research/tree/master/NLP/EMNLP2021-SgSum">code</a>]
        </li>

        <li> <b>[ACL 2021]</b> <u>Wei Li*</u>, Can Gao*, Guochenng Niu*, Xinyan Xiao*, Hao Liu, Jiachen Liu, Hua Wu and Haifeng Wang. <i>UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning</i>. ACL 2021 long paper, Main Conference. (* indicates equal contribution) [<a href="https://aclanthology.org/2021.acl-long.202.pdf">PDF</a>] [<a href="https://unimo-ptm.github.io/">code</a>]
        </li>

        <li> <b>[ACL 2021]</b> Wenhao Wu, <u>Wei Li</u>, Xinyan Xiao, Jiachen Liu, Ziqiang Cao, Sujian Li, Hua Wu and Haifeng Wang. <i>BASS: Boosting Abstractive Summarization with Unified Semantic Graph</i>. ACL 2021 long paper, Main Conference. [<a href="https://aclanthology.org/2021.acl-long.472.pdf">PDF</a>]
        </li>

        <li> <b>[ACL 2021]</b> Zixuan Li, Xiaolong Jin, Saiping Guan, <u>Wei Li</u>, Jiafeng Guo, Yuanzhuo Wang and Xueqi Cheng. <i>Search from History and Reason for Future: Two-stage Reasoning on Temporal Knowledge Graphs</i>. ACL 2021 long paper, Main Conference. [<a href="https://aclanthology.org/2021.acl-long.365.pdf">PDF</a>]
        </li>

        <li> <b>[SIGIR 2021]</b> Zixuan Li, Xiaolong Jin, <u>Wei Li</u>, Saiping Guan, Jiafeng Guo, Huawei Shen, Yuanzhuo Wang and Xueqi Cheng. <i>Temporal Knowledge Graph Reasoning Based on Evolutional Representation Learning</i>. SIGIR2021 Full paper. [<a href="https://arxiv.org/pdf/2104.10353.pdf">PDF</a>] [<a href="https://github.com/Lee-zix/RE-GCN">code</a>]
        </li>

        <li> <b>[ACL 2020]</b> <u>Wei Li</u>, Xinyan Xiao, Jiachen Liu, Hua Wu and Haifeng Wang. <i>Leveraging Graph to Improve Abstractive Multi-Document Summarization</i>. ACL 2020 long paper, Main Conference. [<a href="https://aclanthology.org/2020.acl-main.555.pdf">PDF</a>] [<a href="https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2020-GraphSum">code</a>]
        </li>
        
        <li> <b>[FGCS 2020]</b> <u>Wei Li</u> and Hai Zhuge. <i>Probabilistic inference on uncertain semantic link network and its application in event identification</i>. Future Generation Computer Systems, pp: 32-42, 2020
        </li>

        <li> <b>[TKDE 2019]</b> <u>Wei Li</u> and Hai Zhuge. <i>Abstractive multi-document summarization based on semantic link network</i>. IEEE Transactions on Knowledge and Data Engineering, 2019
        </li>

        <li> <b>[IEEE Access 2019]</b> <u>Wei Li</u>, Dezhi Cheng, Lei He, Yuanzhuo Wang and Xiaolong Jin. <i>Joint Event Extraction Based on Hierarchical Event Schemas from FrameNet</i>. IEEE Access, 2019
        </li>

        <li> <b>[EMNLP 2018]</b> <u>Wei Li</u>, Xinyan Xiao, Yajuan Lyu and Yuanzhuo Wang. <i>Improving neural abstractive document summarization with explicit information selection modeling</i>. Proceedings of EMNLP2018, the 2018 Conference on Empirical Methods in Natural Language Processing.
        </li>

        <li> <b>[EMNLP 2018]</b> <u>Wei Li</u>, Xinyan Xiao, Yajuan Lyu and Yuanzhuo Wang. <i>Improving neural abstractive document summarization with structural regularization</i>. Proceedings of EMNLP2018, the 2018 Conference on Empirical Methods in Natural Language Processing.
        </li>

        <li> <b>[COLING 2016]</b> <u>Wei Li</u>, Lei He and Hai Zhuge. <i>Abstractive news summarization based on event semantic link network</i>. Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers.
        </li>

        <li> <b>[COLING 2016]</b> Lei He, <u>Wei Li</u> and Hai Zhuge. <i>Exploring differential topic models for comparative summarization of scientific papers</i>. Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers.
        </li>

        <li> <b>[EMNLP 2015]</b> <u>Wei Li</u>. <i>Abstractive multi-document summarization with semantic information extraction</i>. Proceedings of EMNLP2015, the 2015 Conference on Empirical Methods in Natural Language Processing.
        </li>
</ul>
</section>


<section id="backgroud">
    <h2>Experience:</h2>
    <ul>
    <li>[Nov 2023 - Now]: Associate Professor, Institute of Computing Technology, <b> Chinese Academy of Sciences</b>, <a href="http://www.ict.ac.cn/sourcedb_ict_cas/cn/jssrck/202401/t20240109_6950572.html">Personal Pages</a>
    <li>[July 2021 - Nov. 2023]: Senior Engineer, NLP & KG Department, <b>Baidu Inc.</b>
    <li>[July 2019 - Oct. 2021]: Postdoc, <b>Baidu Inc. and Beijing University of Posts and Telecommunications</b>. Supervisor: Prof. <a href="https://scholar.google.com/citations?user=jgy4jCAAAAAJ&hl=zh-CN">Haifeng Wang</a> and <a href="https://scs.bupt.edu.cn/info/1092/1327.htm">Junping Du</a>
    </li>
    <li>[Sept. 2012 - June 2019]: PhD, Institute of Computing Technology, <b>Chinese Academy of Sciences</b>. Supervisor: Prof. <a href="https://scholar.google.com/citations?user=v1KzwYEAAAAJ&hl=zh-CN">Yuanzhuo Wang</a>
    </li>
    <li>[Sept. 2008 - June 2012]: B.E, School of Computer Science, <b>Wuhan University</b> 
    </li>
    </ul>
</section>

<br><br>
<hr>
<footer>
<!-- Start of StatCounter Code for Default Guide -->
<div align="center">
    <b><small>&copy; Copyright 2021, Wei Li
    <script type="text/javascript">
        var m = "This page was last updated: " + document.lastModified;
        var p = m.length-8;
        document.writeln("<center>");
        document.write(m.substring(p, 0));
        document.writeln("</center>");
    </script>
    </small>
    </b>
    <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=-eF9XUjQgGKnileSvTRYEZ7YubYoU9uQ3P9Nygw-vuI&cl=ffffff&w=a"></script>

    <!-- Default Statcounter code for My Homepage https://weili-nlp.github.io-->
    <script type="text/javascript">
    var sc_project=12695154; 
    var sc_invisible=0; 
    var sc_security="d7caf4a3"; 
    var scJsHost = "https://";
    document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="site stats"
    href="https://statcounter.com/" target="_blank"><img class="statcounter"
    src="https://c.statcounter.com/12695154/0/d7caf4a3/0/" alt="site stats"
    referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
    <!-- End of Statcounter Code -->

</div>
</footer>

</body>
</html>
